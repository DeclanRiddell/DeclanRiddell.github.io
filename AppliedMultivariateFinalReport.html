<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c20{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:93pt;border-top-color:#000000;border-bottom-style:solid}.c9{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:142pt;border-top-color:#000000;border-bottom-style:solid}.c4{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:135pt;border-top-color:#000000;border-bottom-style:solid}.c16{border-right-style:solid;padding:5pt 5pt 5pt 5pt;border-bottom-color:#000000;border-top-width:1pt;border-right-width:1pt;border-left-color:#000000;vertical-align:top;border-right-color:#000000;border-left-width:1pt;border-top-style:solid;border-left-style:solid;border-bottom-width:1pt;width:109pt;border-top-color:#000000;border-bottom-style:solid}.c42{-webkit-text-decoration-skip:none;color:#000000;font-weight:400;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-size:12pt;font-family:"Arial";font-style:normal}.c8{background-color:#00ff00;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:italic}.c1{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Arial";font-style:normal}.c36{margin-left:72pt;padding-top:0pt;text-indent:0.3pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:51.6pt}.c14{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:italic}.c33{margin-left:72.1pt;padding-top:8.1pt;text-indent:0.8pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:71.8pt}.c34{margin-left:72.1pt;padding-top:30.2pt;text-indent:1pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:53.6pt}.c50{margin-left:71.5pt;padding-top:0pt;text-indent:0.5pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:53.8pt}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:17pt;font-family:"Arial";font-style:normal}.c17{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:15pt;font-family:"Arial";font-style:normal}.c62{margin-left:73pt;padding-top:3pt;text-indent:-1pt;padding-bottom:0pt;line-height:0.8587133884429932;text-align:left;margin-right:52pt}.c23{margin-left:72.2pt;padding-top:2.6pt;text-indent:35.8pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:60.3pt}.c54{margin-left:72.4pt;padding-top:8.1pt;text-indent:-0pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:justify;margin-right:59.8pt}.c29{color:#000000;font-weight:700;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c60{margin-left:72pt;padding-top:33.2pt;text-indent:37.1pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:52.9pt}.c13{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Arial";font-style:normal}.c6{margin-left:72pt;padding-top:33.2pt;text-indent:36.9pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:50.7pt}.c5{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:28pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Arial";font-style:normal}.c58{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c59{margin-left:72pt;padding-top:0pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:left;margin-right:54.7pt}.c35{margin-left:72.2pt;padding-top:33.2pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:center;margin-right:59.9pt}.c12{margin-left:56.2pt;padding-top:0pt;padding-bottom:0pt;line-height:1.121203064918518;text-align:center;margin-right:3pt}.c7{margin-left:53.2pt;padding-top:0pt;padding-bottom:0pt;line-height:0.8983758091926575;text-align:center;margin-right:25.5pt}.c40{padding-top:32.8pt;padding-bottom:0pt;line-height:1.0;text-align:right;margin-right:232.9pt;height:11pt}.c48{margin-left:111.4pt;padding-top:0pt;padding-bottom:0pt;line-height:1.915737271308899;text-align:center;margin-right:84.5pt}.c32{margin-left:73.5pt;padding-top:9.2pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c15{margin-left:7.6pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c47{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;height:11pt}.c19{margin-left:6.7pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c43{margin-left:73.1pt;padding-top:40pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c51{margin-left:7.7pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c28{margin-left:7.3pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c18{margin-left:7.1pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c41{margin-left:6.4pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c45{margin-left:72.9pt;padding-top:1.7pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c61{margin-left:72.9pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c27{margin-left:72.8pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c31{margin-left:8.2pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c10{margin-left:73.5pt;padding-top:15.8pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c44{margin-left:72.8pt;padding-top:12.5pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c22{margin-left:6.9pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c46{margin-left:7.2pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c57{margin-left:7.4pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c26{margin-left:72.9pt;padding-top:2.2pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c24{margin-left:20.2pt;padding-top:5.9pt;padding-bottom:0pt;line-height:0.8505274057388306;text-align:center}.c39{margin-left:6.6pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c21{margin-left:72.8pt;padding-top:2.6pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c56{padding-top:32.8pt;padding-bottom:0pt;line-height:1.0;text-align:right;margin-right:232.9pt}.c49{margin-left:72pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c2{margin-left:6.5pt;padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:left}.c52{margin-left:71.5pt;border-spacing:0;border-collapse:collapse;margin-right:auto}.c53{padding-top:0pt;padding-bottom:0pt;line-height:1.0;text-align:center}.c11{background-color:#ffffff;max-width:592.5pt;padding:70.3pt 19.5pt 0pt 0pt}.c25{height:28pt}.c38{height:27pt}.c55{background-color:#ffff00}.c30{background-color:#ff9900}.c37{background-color:#9900ff}.title{padding-top:24pt;color:#000000;font-weight:700;font-size:36pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:18pt;color:#666666;font-size:24pt;padding-bottom:4pt;font-family:"Georgia";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:24pt;color:#000000;font-weight:700;font-size:24pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-weight:700;font-size:18pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:14pt;color:#000000;font-weight:700;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:12pt;color:#000000;font-weight:700;font-size:12pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:11pt;color:#000000;font-weight:700;font-size:11pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:10pt;color:#000000;font-weight:700;font-size:10pt;padding-bottom:2pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}</style></head><body class="c11 doc-content"><p class="c48"><span class="c5">Feature Analysis and Predictive Modeling with Obesity Data</span></p><p class="c56"><span class="c3">Declan Riddell</span><hr style="page-break-before:always;display:none;"></p><p class="c40"><span class="c3"></span></p><p class="c49"><span class="c17">Abstract: </span></p><p class="c6"><span class="c13">My dataset is a 16 attribute data set with about 2100 rows with no missing values. The data were gathered from an online survey. The dataset provides information on obesity levels with data regarding their diet and physical activity. Contained in the dataset are basic qualifier variables like gender, age, and height. Along with those, there are some interesting fields that I am curious to see if they have a correlation with the level of obesity. Examples would be use of technological devices, smoking, or whether the person monitors their calories on a daily basis. There are some interesting hypotheses you can base off of social norms, for example someone who uses their phone more or plays more video games would be much more likely to be obese based on the implication that they are not very physically active. Or perhaps someone who monitors their calories on a daily basis would be more likely to not be obese, as that type of behavior is usually associated with someone who might be very into lifting weights or maintaining a certain level of physique. </span></p><p class="c43"><span class="c17">Methods: </span></p><p class="c35"><span class="c13">The analysis of the dataset was done through the use of the programming language R. The first steps taken in the analysis were to transform the categorical variables such as family_history_with_overweight, and SMOKE(whether the patient smokes cigarettes or not), into numerical variables that were easier to perform different</span></p><p class="c36"><span class="c13">statistical tests on. These variables were coded into numerical values where the number would correspond to a specific categorical value, such as the number 1 for male, or the number 2 for female. This was done utilizing a function I created in R that would take the field which was provided as a string, turn it into a factor, and then into a numeric. There were a total of 9 variables that had to be encoded: FAVC, CAEC, SMOKE, SCC, CALC, MTRANS, Gender, family_history_with_overweight, and the target NObeyesdad. Once these were encoded, I was able to begin the feature analysis of the data set, starting with the correlation plot of the entire dataset. </span></p><p class="c62"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 529.00px; height: 389.00px;"><img alt="" src="images/image8.png" style="width: 529.00px; height: 389.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c13">Here you can see that the dataset is pretty highly correlated. This can be confirmed with </span></p><p class="c33"><span class="c13">PCA analysis. Normally, when using PCA the goal is to reduce the dimensionality by forcing a higher amount of variance into a smaller subset of components.</span></p><p class="c7"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 685.00px; height: 153.00px;"><img alt="" src="images/image10.png" style="width: 685.00px; height: 153.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c13">The PCA results for this dataset confirm that the dataset is highly correlated as you can </span></p><p class="c54"><span class="c13">see the proportion of the variance is very small for even the first few components. This data is still useful in determining the level of factors we can use to find the optimum set of features. Generally, you want the smallest amount of factors that still represent the </span></p><p class="c21"><span class="c13">largest amount of variance of the dataset. Because PCA proved ineffective in </span></p><p class="c24"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 382.00px; height: 237.00px;"><img alt="" src="images/image9.png" style="width: 382.00px; height: 237.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 386.00px; height: 237.00px;"><img alt="" src="images/image5.png" style="width: 386.00px; height: 237.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c13">compressing the dimensionality of the data, I chose to go with a number of components </span></p><p class="c44"><span class="c13">based on the proportion of the variance.</span></p><p class="c50"><span class="c13">Above are my Factor Analysis tests that I conducted. Based on the desire to maintain at about 70% of the variance, I chose to continue with 8 factors, although you can see that the 8th component does not have any significant correlation with the principal components. This could mainly be due to the fact that the dataset itself is quite small at just over 2100 rows. </span></p><p class="c34"><span class="c13">I chose to use 3 classification techniques in evaluating the dataset for predicting obesity levels: KNN, Random Forrest, and Logistic Regression. For each of these techniques I conducted 4 tests each with different amounts and levels of variable correlation: Full, Highest Correlated Subset(HCS), Lowest Correlated Subset(LCS), Factor Level Subset(FS). The HCS and LCS both consisted of the 3 top variables for their categories respectively. The three highest correlated variables to the target NObeyesdad are Weight, CAEC, and family_history_with_overweight. The three lowest correlated variables are FAF, NCP, and TUE. The next five highest correlated variables, which are included in the FS subset are Age, CH20, CALC, FAVC, and Height.</span></p><p class="c12"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 336.00px; height: 224.00px;"><img alt="" src="images/image4.png" style="width: 336.00px; height: 224.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 358.00px; height: 224.00px;"><img alt="" src="images/image7.png" style="width: 358.00px; height: 224.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 411.00px; height: 279.00px;"><img alt="" src="images/image6.png" style="width: 411.00px; height: 279.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><table class="c52"><tr class="c38"><td class="c20" colspan="1" rowspan="1"><p class="c53"><span class="c58">Accuracy % </span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c57"><span class="c29">K-Nearest Neighbor </span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c39"><span class="c29">Random Forest </span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c46"><span class="c29">Logistic Regression</span></p></td></tr><tr class="c38"><td class="c20" colspan="1" rowspan="1"><p class="c2"><span class="c1">FULL </span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c15"><span class="c14 c55">88%</span><span class="c14">&nbsp;</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c19"><span class="c14 c55">92%</span><span class="c14">&nbsp;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c46"><span class="c14 c55">96%</span></p></td></tr><tr class="c25"><td class="c20" colspan="1" rowspan="1"><p class="c2"><span class="c1">HCS </span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c31"><span class="c8">79%</span><span class="c14">&nbsp;</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c41"><span class="c8">48%</span><span class="c14">&nbsp;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c22"><span class="c8">48%</span></p></td></tr><tr class="c38"><td class="c20" colspan="1" rowspan="1"><p class="c2"><span class="c1">LCS </span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c28"><span class="c14 c30">25%</span><span class="c14">&nbsp;</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c39"><span class="c14 c30">25%</span><span class="c14">&nbsp;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c18"><span class="c14 c30">25%</span></p></td></tr><tr class="c38"><td class="c20" colspan="1" rowspan="1"><p class="c2"><span class="c1">FS </span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c31"><span class="c14 c37">79%</span><span class="c14">&nbsp;</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c19"><span class="c14 c37">97%</span><span class="c14">&nbsp;</span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c46"><span class="c14 c37">97%</span></p></td></tr><tr class="c25"><td class="c20" colspan="1" rowspan="1"><p class="c2"><span class="c1">MEAN </span></p></td><td class="c4" colspan="1" rowspan="1"><p class="c51"><span class="c14">68% </span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c22"><span class="c14">66% </span></p></td><td class="c9" colspan="1" rowspan="1"><p class="c57"><span class="c14">67%</span></p></td></tr></table><p class="c47"><span class="c0"></span></p><p class="c47"><span class="c0"></span></p><p class="c59"><span class="c13">You can see that the KNN model had a peak performance with the FULL set of features with an 88% accuracy rate. The RF, and LR models had their peak performances with the FS subset. My hypothesis for why the LCS models all performed equally at 25% would be due to the size of the sample. With the dataset being only 2111 observations, there is not as much for these models to learn from as you would normally desire. For each of the models I created a Confusion Matrix and used the predicted values against the actual values from a train/test split in the dataset. Each confusion matrix for the peak performances of the models are as follows:</span></p><p class="c61"><span class="c42">KNN -</span><span class="c13">&nbsp;</span></p><p class="c32"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 306.00px; height: 219.00px;"><img alt="" src="images/image2.png" style="width: 306.00px; height: 219.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c45"><span class="c42">RF -</span><span class="c13">&nbsp;</span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 335.00px; height: 215.00px;"><img alt="" src="images/image1.png" style="width: 335.00px; height: 215.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c26"><span class="c42">LR -</span></p><p class="c10"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 335.00px; height: 221.00px;"><img alt="" src="images/image3.png" style="width: 335.00px; height: 221.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c27"><span class="c17">Conclusion: </span></p><p class="c60"><span class="c13">I am skeptical of the RF data because of some of the issues I ran into when creating and running the models. Because of the small sample size, I was unable to generate a desirable number of trees for the model to make predictions, having to go as low as 15 trees in order to get a proper set of predictions. This indicates an area for improvement without too much analysis. The other models would surely benefit greatly from an increased sample size as well.Based on the data I would assert Logistic Regression as the ideal technique to build a predictive model for this dataset. Although the average accuracy is the highest with KNN I have some doubts about the efficacy of the model for this dataset based on the discrepancy between the FULL and FS performance. Because of the high correlation within the dataset, the FS subset becomes more important, as we can confirm with the performance of the other two models, that there is likely some redundancy in the features. I would hypothesize that with more data the mean accuracy of each of the models would increase. </span></p><p class="c23"><span class="c13">After this analysis, I have come to the conclusion that these models would likely see an increase in performance with a larger sample size. I have also concluded that this dataset does not answer any major questions on its own. After analyzing the dataset and generating a model with a high accuracy, I would say that this could better serve in conjunction with data relating to Cardiovascular Diseases. CVD is the main cause of mortality globally and developing models to help detect early stages of CVD linked with obesity could be valuable.</span></p></body></html>